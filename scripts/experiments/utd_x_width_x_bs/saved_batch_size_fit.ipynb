{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from scripts.core.fitting import fit_quadratic, params_to_width\n",
    "from scripts.core.bootstrapping import (\n",
    "    predict_inverse_power_product,\n",
    "    predict_sum_of_powerlaw_shared_exponent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = [\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 128, 178632),\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 256, 619208),\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 512, 2286792),\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 1024, 8767688),\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 2048, 34312392),\n",
    "    ('h1-crawl-v0', 'humanoid_bench', 4096, 135733448),\n",
    "    ('h1-pole-v0', 'humanoid_bench', 256, 619208),\n",
    "    ('h1-pole-v0', 'humanoid_bench', 512, 2286792),\n",
    "    ('h1-pole-v0', 'humanoid_bench', 1024, 8767688),\n",
    "    ('h1-pole-v0', 'humanoid_bench', 2048, 34312392),\n",
    "    ('h1-pole-v0', 'humanoid_bench', 4096, 135733448),\n",
    "    ('h1-stand-v0', 'humanoid_bench', 256, 619208),\n",
    "    ('h1-stand-v0', 'humanoid_bench', 512, 2286792),\n",
    "    ('h1-stand-v0', 'humanoid_bench', 1024, 8767688),\n",
    "    ('h1-stand-v0', 'humanoid_bench', 2048, 34312392),\n",
    "    ('h1-stand-v0', 'humanoid_bench', 4096, 135733448),\n",
    "    ('humanoid-stand', 'dmc', 128, 183240),\n",
    "    ('humanoid-stand', 'dmc', 256, 628424),\n",
    "    ('humanoid-stand', 'dmc', 512, 2305224),\n",
    "    ('humanoid-stand', 'dmc', 1024, 8804552),\n",
    "    ('humanoid-stand', 'dmc', 2048, 34386120),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inverse_power_product`, i.e. $B^* \\sim \\dfrac{a_{\\text{env}}}{\\sigma^{\\alpha_{\\text{env}}} \\left( 1 + (b_{\\text{env}} / N)^{c_{\\text{env}}} \\right) }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_name</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>alpha</th>\n",
       "      <th>a_unscaled</th>\n",
       "      <th>b_unscaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h1-crawl-v0</td>\n",
       "      <td>54406.086168</td>\n",
       "      <td>2.656953e+10</td>\n",
       "      <td>0.554514</td>\n",
       "      <td>0.479077</td>\n",
       "      <td>130.488638</td>\n",
       "      <td>148738.896038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1-pole-v0</td>\n",
       "      <td>45553.278728</td>\n",
       "      <td>2.151064e+10</td>\n",
       "      <td>0.648595</td>\n",
       "      <td>-0.048744</td>\n",
       "      <td>100.888729</td>\n",
       "      <td>9406.470840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h1-stand-v0</td>\n",
       "      <td>1658.998085</td>\n",
       "      <td>8.217601e+05</td>\n",
       "      <td>3.105090</td>\n",
       "      <td>0.382536</td>\n",
       "      <td>1.625321</td>\n",
       "      <td>1.327115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humanoid-stand</td>\n",
       "      <td>1301.950726</td>\n",
       "      <td>4.731815e+06</td>\n",
       "      <td>0.384982</td>\n",
       "      <td>0.493316</td>\n",
       "      <td>3.237266</td>\n",
       "      <td>25.823049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         env_name             a             b         c     alpha  a_unscaled  \\\n",
       "0     h1-crawl-v0  54406.086168  2.656953e+10  0.554514  0.479077  130.488638   \n",
       "1      h1-pole-v0  45553.278728  2.151064e+10  0.648595 -0.048744  100.888729   \n",
       "2     h1-stand-v0   1658.998085  8.217601e+05  3.105090  0.382536    1.625321   \n",
       "3  humanoid-stand   1301.950726  4.731815e+06  0.384982  0.493316    3.237266   \n",
       "\n",
       "      b_unscaled  \n",
       "0  148738.896038  \n",
       "1    9406.470840  \n",
       "2       1.327115  \n",
       "3      25.823049  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_params_path = (\n",
    "    '../saved_fits/utd_critic_params_best_bs_bootstrap_mean_inverse_power_product_250505.npy'\n",
    ")\n",
    "params_dict = np.load(batch_size_params_path, allow_pickle=True).item()\n",
    "\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            'env_name': k,\n",
    "            'a': params[0],\n",
    "            'b': params[1],\n",
    "            'c': params[2],\n",
    "            'alpha': params[3],\n",
    "            'a_unscaled': params[4],\n",
    "            'b_unscaled': params[5],\n",
    "        }\n",
    "        for k, params in params_dict.items()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_predictor = lambda df: predict_inverse_power_product(\n",
    "    df, ['utd', 'critic_params'], params_dict\n",
    ")\n",
    "\n",
    "\n",
    "def make_batch_size_fit_df():\n",
    "    utds = [1, 2, 4, 8, 16]\n",
    "\n",
    "    inputs = [\n",
    "        {\n",
    "            'env_name': env_name,\n",
    "            'benchmark': benchmark,\n",
    "            'utd': utd,\n",
    "            'critic_width': critic_width,\n",
    "            'critic_params': critic_params,\n",
    "        }\n",
    "        for utd in utds\n",
    "        for env_name, benchmark, critic_width, critic_params in model_sizes\n",
    "    ]\n",
    "    batch_size_fit_df = pd.DataFrame(inputs)\n",
    "    batch_size_fit_df['fitted_batch_size'] = batch_size_predictor(batch_size_fit_df)\n",
    "    batch_size_fit_df['batch_size_rounded'] = (\n",
    "        np.round(batch_size_fit_df['fitted_batch_size'] / 16).astype(int) * 16\n",
    "    )\n",
    "\n",
    "    interpolate_df = batch_size_fit_df.query('utd <= 8 and critic_width <= 2048').reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    extrapolate_df = batch_size_fit_df.query('utd > 8 or critic_width > 2048').reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    interpolate_df.to_csv(\n",
    "        'proposed_hparams/interpolate_batch_size_inverse_product_250505.csv', index=False\n",
    "    )\n",
    "    extrapolate_df.to_csv(\n",
    "        'proposed_hparams/extrapolate_batch_size_inverse_product_250505.csv', index=False\n",
    "    )\n",
    "\n",
    "\n",
    "make_batch_size_fit_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_interpolate_batch_size_fit_df():\n",
    "    model_size_df = pd.DataFrame(\n",
    "        model_sizes, columns=['env_name', 'benchmark', 'critic_width', 'critic_params']\n",
    "    )\n",
    "    utds = [3, 6, 12]\n",
    "    critic_widths = (\n",
    "        np.round(np.array([128, 256, 512, 1024, 2048]) * np.sqrt(2) / 16).astype(int) * 16\n",
    "    )\n",
    "    a, b, c = fit_quadratic(model_size_df['critic_width'], model_size_df['critic_params'])\n",
    "    critic_params = a * critic_widths**2 + b * critic_widths + c\n",
    "    env_to_model_size = {\n",
    "        'h1-crawl-v0': (critic_widths[1:], critic_params[1:]),\n",
    "        'h1-pole-v0': (critic_widths[1:-1], critic_params[1:-1]),\n",
    "        'h1-stand-v0': (critic_widths[1:-1], critic_params[1:-1]),\n",
    "        'humanoid-stand': (critic_widths[:-1], critic_params[:-1]),\n",
    "    }\n",
    "\n",
    "    inputs = [\n",
    "        {\n",
    "            'env_name': env_name,\n",
    "            'benchmark': 'humanoid_bench' if env_name.startswith('h1') else 'dmc',\n",
    "            'utd': utd,\n",
    "            'critic_width': critic_width,\n",
    "            'critic_params': critic_params_,\n",
    "        }\n",
    "        for utd in utds\n",
    "        for env_name, (critic_widths, critic_params) in env_to_model_size.items()\n",
    "        for (critic_width, critic_params_) in zip(critic_widths, critic_params)\n",
    "    ]\n",
    "    batch_size_fit_df = pd.DataFrame(inputs)\n",
    "    batch_size_fit_df['fitted_batch_size'] = batch_size_predictor(batch_size_fit_df)\n",
    "    batch_size_fit_df['batch_size_rounded'] = (\n",
    "        np.round(batch_size_fit_df['fitted_batch_size'] / 16).astype(int) * 16\n",
    "    )\n",
    "\n",
    "    batch_size_fit_df.to_csv(\n",
    "        'proposed_hparams/interpolate_batch_size_inverse_product_250510.csv', index=False\n",
    "    )\n",
    "\n",
    "\n",
    "make_interpolate_batch_size_fit_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remake_utd3_batch_size_fit_df():\n",
    "    model_size_df = pd.DataFrame(\n",
    "        model_sizes, columns=['env_name', 'benchmark', 'critic_width', 'critic_params']\n",
    "    )\n",
    "    critic_widths = (\n",
    "        np.round(np.array([128, 256, 512, 1024, 2048]) * np.sqrt(2) / 16).astype(int) * 16\n",
    "    )\n",
    "    a, b, c = fit_quadratic(model_size_df['critic_width'], model_size_df['critic_params'])\n",
    "    critic_params = a * critic_widths**2 + b * critic_widths + c\n",
    "    env_to_model_size = {\n",
    "        'h1-crawl-v0': (critic_widths[1:], critic_params[1:] + [4096]),\n",
    "        'h1-pole-v0': (critic_widths[1:-1], critic_params[1:-1] + [4096]),\n",
    "        'h1-stand-v0': (critic_widths[1:-1], critic_params[1:-1] + [4096]),\n",
    "        'humanoid-stand': (critic_widths[:-1], critic_params[:-1] + [4096]),\n",
    "    }\n",
    "\n",
    "    inputs = [\n",
    "        {\n",
    "            'env_name': env_name,\n",
    "            'benchmark': 'humanoid_bench' if env_name.startswith('h1') else 'dmc',\n",
    "            'utd': utd,\n",
    "            'critic_width': critic_width,\n",
    "            'critic_params': critic_params_,\n",
    "        }\n",
    "        for utd in [3]\n",
    "        for env_name, (critic_widths, critic_params) in env_to_model_size.items()\n",
    "        for (critic_width, critic_params_) in zip(critic_widths, critic_params)\n",
    "    ]\n",
    "    batch_size_fit_df = pd.DataFrame(inputs)\n",
    "    batch_size_fit_df['fitted_batch_size'] = batch_size_predictor(batch_size_fit_df)\n",
    "    batch_size_fit_df['batch_size_rounded'] = (\n",
    "        np.round(batch_size_fit_df['fitted_batch_size'] / 16).astype(int) * 16\n",
    "    )\n",
    "\n",
    "    batch_size_fit_df.to_csv(\n",
    "        'proposed_hparams/utd3_batch_size_inverse_product_250513.csv', index=False\n",
    "    )\n",
    "\n",
    "\n",
    "remake_utd3_batch_size_fit_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute optimal hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finger-turn\n",
      "quadruped-run\n"
     ]
    }
   ],
   "source": [
    "mine_data_efficiency_params_path = (\n",
    "    '../saved_fits/utd_critic_params_time_to_threshold_sum_of_powerlaw_shared_exp_250508.npy'\n",
    ")\n",
    "mine_data_efficiency_params_dict = np.load(\n",
    "    mine_data_efficiency_params_path, allow_pickle=True\n",
    ").item()\n",
    "mine_data_efficiency_predictor = lambda df: predict_sum_of_powerlaw_shared_exponent(\n",
    "    df, ['utd', 'critic_params'], mine_data_efficiency_params_dict\n",
    ")\n",
    "\n",
    "dmc_data_efficiency_params_path = (\n",
    "    '../saved_fits/dmc_utd_critic_params_last_crossing_sum_of_powerlaw_shared_exp_250520.npy'\n",
    ")\n",
    "dmc_data_efficiency_params_dict = np.load(dmc_data_efficiency_params_path, allow_pickle=True).item()\n",
    "dmc_data_efficiency_predictor = lambda df: predict_sum_of_powerlaw_shared_exponent(\n",
    "    df, ['utd', 'critic_params'], dmc_data_efficiency_params_dict\n",
    ")\n",
    "\n",
    "dog_humanoid_data_efficiency_params_path = '../saved_fits/dog_humanoid_utd_critic_params_last_crossing_sum_of_powerlaw_shared_exp_250520.npy'\n",
    "dog_humanoid_data_efficiency_params_dict = np.load(\n",
    "    dog_humanoid_data_efficiency_params_path, allow_pickle=True\n",
    ").item()\n",
    "dog_humanoid_data_efficiency_predictor = lambda df: predict_sum_of_powerlaw_shared_exponent(\n",
    "    df, ['utd', 'critic_params'], dog_humanoid_data_efficiency_params_dict\n",
    ")\n",
    "\n",
    "\n",
    "def make_compute_optimal_hparams():\n",
    "    compute_budgets_per_env = {\n",
    "        'h1-stand-v0': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'h1-crawl-v0': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'h1-pole-v0': [2e16, 4e16, 8e16, 16e16, 32e16],\n",
    "        'humanoid-stand': [0.25e16, 0.5e16, 1e16, 2e16, 4e16],\n",
    "        'acrobot-swingup': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'cheetah-run': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'dog-run': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'finger-turn': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'fish-swim': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'hopper-hop': [0.5e16, 1e16, 2e16, 4e16, 8e16],\n",
    "        'pendulum-swingup': [0.5e16, 1e16, 2e16, 4e16, 8e16],\n",
    "        'quadruped-run': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'walker-run': [0.25e16, 0.5e16, 1e16, 2e16, 4e16],\n",
    "        'dog-stand': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'dog-trot': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'dog-walk': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'humanoid-run': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "        'humanoid-walk': [1e16, 2e16, 4e16, 8e16, 16e16],\n",
    "    }\n",
    "    model_size_df = pd.DataFrame(\n",
    "        model_sizes, columns=['env_name', 'benchmark', 'critic_width', 'critic_params']\n",
    "    )\n",
    "    mine_fit_df = pd.read_csv(\n",
    "        'compute_fits/compute_optimal_fits_250508_234641.csv',\n",
    "    )\n",
    "    dmc_easy_df = pd.read_csv(\n",
    "        'compute_fits/dmc_compute_optimal_shared_exp_fits_250520.csv',\n",
    "    )\n",
    "    dmc_dog_humanoid_df = pd.read_csv(\n",
    "        'compute_fits/dog_humanoid_compute_optimal_shared_exp_fits_250520.csv',\n",
    "    ).query('env_name != \"humanoid-stand\"')\n",
    "    combined_df = pd.concat([mine_fit_df, dmc_easy_df, dmc_dog_humanoid_df])\n",
    "    combined_df['benchmark'] = combined_df['env_name'].apply(\n",
    "        lambda x: 'humanoid_bench' if x.startswith('h1') else 'dmc'\n",
    "    )\n",
    "\n",
    "    slopes, intercepts = {}, {}\n",
    "    for _, row in combined_df.iterrows():\n",
    "        slopes[row['env_name']] = row['slope']\n",
    "        intercepts[row['env_name']] = row['intercept']\n",
    "\n",
    "    batch_size = 256  # TODO\n",
    "    utds = np.logspace(np.log10(1e-3), np.log10(1e3), 1000)\n",
    "    results = []\n",
    "\n",
    "    for (env, benchmark), _ in combined_df.groupby(['env_name', 'benchmark']):\n",
    "        slope, intercept = slopes[env], intercepts[env]\n",
    "        critic_params = np.exp(intercept) ** (-1 / slope) * utds ** (1 / slope)\n",
    "        if env in mine_fit_df['env_name'].values:\n",
    "            data_efficiency_predictor = mine_data_efficiency_predictor\n",
    "        elif env in dmc_easy_df['env_name'].values:\n",
    "            data_efficiency_predictor = dmc_data_efficiency_predictor\n",
    "        elif env in dmc_dog_humanoid_df['env_name'].values:\n",
    "            data_efficiency_predictor = dog_humanoid_data_efficiency_predictor\n",
    "        else:\n",
    "            raise ValueError(f'{env} not found in any fit')\n",
    "        data_efficiency = data_efficiency_predictor(\n",
    "            pd.DataFrame({'env_name': env, 'utd': utds, 'critic_params': critic_params})\n",
    "        )\n",
    "        compute = 10 * batch_size * critic_params * utds * data_efficiency\n",
    "        for budget in compute_budgets_per_env[env]:\n",
    "            idx = np.max(np.where(compute <= budget))\n",
    "            utd, critic_params_ = utds[idx], critic_params[idx]\n",
    "            results.append(\n",
    "                {\n",
    "                    'env_name': env,\n",
    "                    'benchmark': benchmark,\n",
    "                    'utd': utd,\n",
    "                    'critic_params': critic_params_,\n",
    "                    'compute_budget': budget,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Use model size from existing data and only batch size fit for mine\n",
    "    fake_env_mapping = {\n",
    "        env: model_size_df.query(f'benchmark == \"{benchmark}\"')['env_name'].values[0]\n",
    "        for (env, benchmark), _ in combined_df.groupby(['env_name', 'benchmark'])\n",
    "    }\n",
    "    actual_envs = df['env_name'].tolist()\n",
    "    df['env_name'] = df['env_name'].map(fake_env_mapping)\n",
    "    df['critic_width'] = params_to_width(model_size_df, df, 'critic_params')\n",
    "    use_bs_prediction = [env in mine_fit_df['env_name'].values for env in actual_envs]\n",
    "    df['batch_size'] = np.where(use_bs_prediction, batch_size_predictor(df), 256)\n",
    "    df['env_name'] = actual_envs\n",
    "\n",
    "    df['batch_size_rounded'] = np.round(df['batch_size'] / 16).astype(int) * 16\n",
    "    df['critic_width'] = (df['critic_width'] / 16).astype(int) * 16\n",
    "    df['utd'] = np.round(df['utd']).astype(int)\n",
    "\n",
    "    df = df.query('utd >= 1 and utd <= 25')\n",
    "\n",
    "    df[df['env_name'].isin(mine_fit_df['env_name'].values)].to_csv(\n",
    "        'proposed_hparams/hb_compute_optimal_250520.csv', index=False\n",
    "    )\n",
    "    df[~df['env_name'].isin(mine_fit_df['env_name'].values)].to_csv(\n",
    "        'proposed_hparams/dmc_compute_optimal_shared_exp_250520.csv', index=False\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "for env, group in make_compute_optimal_hparams().groupby('env_name'):\n",
    "    if len(group) < 5:\n",
    "        print(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scale_rl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
